{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test\n",
      "0     1\n",
      "1     2\n",
      "2     3\n",
      "3     4\n",
      "4     5\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6 entries, 0 to 5\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   test    6 non-null      int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 176.0 bytes\n",
      "None\n",
      "(6, 1)\n",
      "           test\n",
      "count  6.000000\n",
      "mean   3.500000\n",
      "std    1.870829\n",
      "min    1.000000\n",
      "25%    2.250000\n",
      "50%    3.500000\n",
      "75%    4.750000\n",
      "max    6.000000\n",
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]]\n",
      "Index(['test'], dtype='object')\n",
      "RangeIndex(start=0, stop=6, step=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "my_list = [1,2,3,4,5,6]\n",
    "homelessness = pd.DataFrame(my_list, columns = ['test'])\n",
    "\n",
    "\n",
    "# Print the head of the homelessness data\n",
    "print(homelessness.head())\n",
    "\n",
    "# Print information about homelessness\n",
    "print(homelessness.info())\n",
    "\n",
    "# Print the shape of homelessness\n",
    "print(homelessness.shape)\n",
    "\n",
    "# Print a description of homelessness\n",
    "print(homelessness.describe())\n",
    "\n",
    "# Import pandas using the alias pd\n",
    "import pandas as pd\n",
    "# Print the values of homelessness\n",
    "print (homelessness.values)\n",
    "\n",
    "# Print the column index of homelessness\n",
    "print (homelessness.columns)\n",
    "\n",
    "# Print the row index of homelessness\n",
    "print (homelessness.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test\n",
      "0     1\n",
      "1     2\n",
      "2     3\n",
      "3     4\n",
      "4     5\n"
     ]
    }
   ],
   "source": [
    "# Sort homelessness by descending family members\n",
    "\n",
    "homelessness_fam = homelessness.sort_values(\"family_members\", ascending=False)\n",
    "\n",
    "# Print the top few rows\n",
    "print (homelessness_fam.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test\n",
      "5     6\n",
      "4     5\n",
      "3     4\n",
      "2     3\n",
      "1     2\n"
     ]
    }
   ],
   "source": [
    "# Sort homelessness by region, then descending family members\n",
    "homelessness_reg_fam = homelessness.sort_values('test', ascending = False)\n",
    "\n",
    "# Print the top few rows\n",
    "print (homelessness_reg_fam.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test\n",
      "0     1\n",
      "1     2\n",
      "2     3\n",
      "3     4\n",
      "4     5\n"
     ]
    }
   ],
   "source": [
    "# Sort homelessness by region, then descending family members\n",
    "homelessness_reg_fam = homelessness.sort_values(['test', 'test'], ascending = [1,0])\n",
    "\n",
    "# Print the top few rows\n",
    "print (homelessness_reg_fam.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test  test\n",
      "0     1     1\n",
      "1     2     2\n",
      "2     3     3\n",
      "3     4     4\n",
      "4     5     5\n",
      "Index(['test'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Select the state and family_members columns\n",
    "state_fam = homelessness[['test', 'test']]\n",
    "\n",
    "# Print the head of the result\n",
    "print (state_fam.head())\n",
    "print (homelessness.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test\n",
      "0     1\n",
      "1     2\n",
      "2     3\n",
      "3     4\n",
      "4     5\n",
      "5     6\n"
     ]
    }
   ],
   "source": [
    "# Filter for rows where individuals is greater than 10000\n",
    "ind_gt_10k = homelessness[homelessness['test'] < 1000]\n",
    "\n",
    "# See the result\n",
    "print(ind_gt_10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test\n",
      "0     1\n"
     ]
    }
   ],
   "source": [
    "# Filter for rows where family_members is less than 1000 \n",
    "# and region is Pacific\n",
    "fam_lt_1k_pac = homelessness[(homelessness['test'] < 1000) & (homelessness['test'] == 1)]\n",
    "\n",
    "# See the result\n",
    "print(fam_lt_1k_pac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        state\n",
      "0  California\n",
      "1     Arizona\n",
      "2      Nevada\n",
      "3        Utah\n"
     ]
    }
   ],
   "source": [
    "# The Mojave Desert states\n",
    "\n",
    "homelessness = [\"California\", \"Arizona\", \"Nevada\", \"Utah\"]\n",
    "homelessness = pd.DataFrame(homelessness, columns = [\"state\"])\n",
    "\n",
    "canu = [\"California\", \"Arizona\", \"Nevada\", \"Utah\"]\n",
    "\n",
    "# Filter for rows in the Mojave Desert states\n",
    "mojave_homelessness = homelessness[homelessness[\"state\"].isin(canu)]\n",
    "\n",
    "# See the result\n",
    "print(mojave_homelessness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add total col as sum of individuals and family_members\n",
    "homelessness[\"total\"] = homelessness[\"individuals\"] + homelessness[\"family_members\"]\n",
    " \n",
    "# Add p_individuals col as proportion of individuals\n",
    "homelessness[\"p_individuals\"] = homelessness[\"individuals\"]/(homelessness[\"individuals\"] + homelessness[\"family_members\"])\n",
    "\n",
    "# See the result\n",
    "print(homelessness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create indiv_per_10k col as homeless individuals per 10k state pop\n",
    "homelessness[\"indiv_per_10k\"] = 10000 * homelessness[\"individuals\"] / homelessness[\"state_pop\"] \n",
    "\n",
    "# Subset rows for indiv_per_10k greater than 20\n",
    "high_homelessness = homelessness[homelessness[\"indiv_per_10k\"] > 20]\n",
    "\n",
    "# Sort high_homelessness by descending indiv_per_10k\n",
    "high_homelessness_srt = high_homelessness.sort_values(\"indiv_per_10k\", ascending=False)\n",
    "\n",
    "# From high_homelessness_srt, select the state and indiv_per_10k cols\n",
    "result = high_homelessness_srt[[\"state\", \"indiv_per_10k\"]]\n",
    "\n",
    "# See the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the head of the sales DataFrame\n",
    "print (sales.head())\n",
    "\n",
    "# Print the info about the sales DataFrame\n",
    "print (sales.info())\n",
    "\n",
    "# Print the mean of weekly_sales\n",
    "print (sales['weekly_sales'].mean())\n",
    "\n",
    "# Print the median of weekly_sales\n",
    "print (sales['weekly_sales'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the maximum of the date column\n",
    "print (sales[\"date\"].max())\n",
    "\n",
    "# Print the minimum of the date column\n",
    "print (sales[\"date\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A custom IQR function\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "    \n",
    "# Print IQR of the temperature_c column\n",
    "print(sales[\"temperature_c\"].agg(iqr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A custom IQR function\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "# Update to print IQR of temperature_c, fuel_price_usd_per_l, & unemployment\n",
    "print(str(sales[\"temperature_c\"].agg(iqr)) + str(sales[\"fuel_price_usd_per_l\"].agg(iqr)) + str(sales[\"unemployment\"].agg(iqr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A custom IQR function\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "# Update to print IQR of temperature_c, fuel_price_usd_per_l, & unemployment\n",
    "print(sales[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg(iqr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NumPy and create custom IQR function\n",
    "import numpy as np\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "# Update to print IQR and median of temperature_c, fuel_price_usd_per_l, & unemployment\n",
    "print(sales[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg([iqr,np.median]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort sales_1_1 by date\n",
    "sales_1_1 = sales_1_1.sort_values(\"date\")\n",
    "\n",
    "# Get the cumulative sum of weekly_sales, add as cum_weekly_sales col\n",
    "sales_1_1['cum_weekly_sales'] = sales_1_1[\"weekly_sales\"].cumsum()\n",
    "\n",
    "# Get the cumulative max of weekly_sales, add as cum_max_sales col\n",
    "sales_1_1['cum_max_sales'] = sales_1_1[\"weekly_sales\"].cummax()\n",
    "\n",
    "# See the columns you calculated\n",
    "print(sales_1_1[[\"date\", \"weekly_sales\", \"cum_weekly_sales\", \"cum_max_sales\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate store/type combinations\n",
    "store_types = sales.drop_duplicates(subset=[\"store\", \"type\"])\n",
    "print(store_types.head())\n",
    "\n",
    "# Drop duplicate store/department combinations\n",
    "store_depts = sales.drop_duplicates(subset=[\"store\", \"department\"])\n",
    "print(store_depts.head())\n",
    "\n",
    "# Subset the rows that are holiday weeks and drop duplicate dates\n",
    "holiday_dates = sales[sales[\"is_holiday\"]].drop_duplicates(subset=\"date\")\n",
    "\n",
    "# Print date col of holiday_dates\n",
    "print(holiday_dates[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of stores of each type\n",
    "print(store_types)\n",
    "store_counts = store_types[\"type\"].value_counts()\n",
    "print(store_counts)\n",
    "\n",
    "# Get the proportion of stores of each type\n",
    "store_props = store_types[\"type\"].value_counts(normalize=True)\n",
    "print(store_props)\n",
    "\n",
    "# Count the number of each department number and sort\n",
    "dept_counts_sorted = store_depts[\"department\"].value_counts()\n",
    "print(dept_counts_sorted)\n",
    "\n",
    "# Get the proportion of departments of each number and sort\n",
    "dept_props_sorted = store_depts[\"department\"].value_counts(sort=True, normalize=True)\n",
    "print(dept_props_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc total weekly sales\n",
    "sales_all = sales[\"weekly_sales\"].sum()\n",
    "\n",
    "# Subset for type A stores, calc total weekly sales\n",
    "sales_A = sales[sales[\"type\"] == \"A\"][\"weekly_sales\"].sum()\n",
    "\n",
    "# Subset for type B stores, calc total weekly sales\n",
    "sales_B = sales[sales[\"type\"] == \"B\"][\"weekly_sales\"].sum()\n",
    "\n",
    "# Subset for type C stores, calc total weekly sales\n",
    "sales_C = sales[sales[\"type\"] == \"C\"][\"weekly_sales\"].sum()\n",
    "\n",
    "# Get proportion for each type\n",
    "sales_propn_by_type = [sales_A, sales_B, sales_C] / (sales_A + sales_B + sales_C )\n",
    "print(sales_propn_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From previous step\n",
    "sales_by_type = sales.groupby(\"type\")[\"weekly_sales\"].sum()\n",
    "\n",
    "# Group by type and is_holiday; calc total weekly sales\n",
    "sales_by_type_is_holiday = sales.groupby([\"type\", \"is_holiday\"])[\"weekly_sales\"].sum()\n",
    "print(sales_by_type_is_holiday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NumPy with the alias np\n",
    "import numpy as np\n",
    "\n",
    "# For each store type, aggregate weekly_sales: get min, max, mean, and median\n",
    "sales_stats = sales.groupby(\"type\")[\"weekly_sales\"].agg([np.min, np.max, np.mean, np.median])\n",
    "\n",
    "# Print sales_stats\n",
    "print(sales_stats)\n",
    "\n",
    "# For each store type, aggregate unemployment and fuel_price_usd_per_l: get min, max, mean, and median\n",
    "unemp_fuel_stats = sales.groupby(\"type\")[[\"unemployment\", \"fuel_price_usd_per_l\"]].agg([np.min, np.max, np.mean, np.median])\n",
    "\n",
    "# Print unemp_fuel_stats\n",
    "print(unemp_fuel_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NumPy as np\n",
    "import numpy as np\n",
    "\n",
    "# Pivot for mean and median weekly_sales for each store type\n",
    "mean_med_sales_by_type = sales.pivot_table(index=\"type\", values = 'weekly_sales', aggfunc=['mean', 'median'])\n",
    "\n",
    "# Print mean_med_sales_by_type\n",
    "print(mean_med_sales_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot for mean weekly_sales by store type and holiday \n",
    "mean_sales_by_type_holiday = sales.pivot_table(index = \"type\", values = \"weekly_sales\", columns = \"is_holiday\")\n",
    "\n",
    "# Print mean_sales_by_type_holiday\n",
    "print(mean_sales_by_type_holiday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print mean weekly_sales by department and type; fill missing values with 0\n",
    "print(sales.pivot_table(index = \"type\", values = \"weekly_sales\", columns = \"department\", fill_value = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the mean weekly_sales by department and type; fill missing values with 0s; sum all rows and cols\n",
    "print(sales.pivot_table(values=\"weekly_sales\", index=\"department\", columns=\"type\", fill_value =0, margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at temperatures\n",
    "print(temperatures)\n",
    "\n",
    "# Index temperatures by city\n",
    "temperatures_ind = temperatures.set_index(\"city\")\n",
    "\n",
    "# Look at temperatures_ind\n",
    "print(temperatures_ind)\n",
    "\n",
    "# Reset the index, keeping its contents\n",
    "print(temperatures_ind.reset_index())\n",
    "\n",
    "# Reset the index, dropping its contents\n",
    "print(temperatures_ind.reset_index(drop = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of cities to subset on\n",
    "cities = [\"Moscow\", \"Saint Petersburg\"]\n",
    "\n",
    "# Subset temperatures using square brackets\n",
    "print(temperatures[temperatures[\"city\"].isin(cities)])\n",
    "\n",
    "# Subset temperatures_ind using .loc[]\n",
    "print(temperatures_ind.loc[cities])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index temperatures by country & city\n",
    "temperatures_ind = temperatures.set_index([\"country\", \"city\"])\n",
    "\n",
    "# List of tuples: Brazil, Rio De Janeiro & Pakistan, Lahore\n",
    "rows_to_keep = [(\"Brazil\", \"Rio De Janeiro\"), (\"Pakistan\", \"Lahore\")]\n",
    "\n",
    "# Subset for rows to keep\n",
    "print(temperatures_ind.loc[rows_to_keep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort temperatures_ind by index values\n",
    "print(temperatures_ind.sort_index())\n",
    "\n",
    "# Sort temperatures_ind by index values at the city level\n",
    "print(temperatures_ind.sort_index(level=\"city\"))\n",
    "\n",
    "# Sort temperatures_ind by country then descending city\n",
    "print(temperatures_ind.sort_index(level=[\"country\", \"city\"], ascending = [True, False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the index of temperatures_ind\n",
    "temperatures_srt = temperatures_ind.sort_index()\n",
    "\n",
    "# Subset rows from Pakistan to Russia\n",
    "print(temperatures_srt.loc[\"Pakistan\" : \"Russia\"])\n",
    "\n",
    "# Try to subset rows from Lahore to Moscow\n",
    "print(temperatures_srt.loc[\"Lahore\" : \"Moscow\"])\n",
    "\n",
    "# Subset rows from Pakistan, Lahore to Russia, Moscow\n",
    "print(temperatures_srt.loc[(\"Pakistan\", \"Lahore\") : (\"Russia\", \"Moscow\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset rows from India, Hyderabad to Iraq, Baghdad\n",
    "print(temperatures_srt.loc[(\"India\", \"Hyderabad\"):(\"Iraq\", \"Baghdad\")])\n",
    "\n",
    "# Subset columns from date to avg_temp_c\n",
    "print(temperatures_srt.loc[:, \"date\":\"avg_temp_c\"])\n",
    "\n",
    "# Subset in both directions at once\n",
    "print(temperatures_srt.loc[(\"India\", \"Hyderabad\"):(\"Iraq\", \"Baghdad\"), \"date\":\"avg_temp_c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Boolean conditions to subset temperatures for rows in 2010 and 2011\n",
    "temperatures_bool = temperatures[(temperatures[\"date\"] >= \"2010-01-01\") & (temperatures[\"date\"] <= \"2011-12-31\")]\n",
    "print(temperatures_bool)\n",
    "\n",
    "# Set date as an index\n",
    "temperatures_ind = temperatures.set_index(\"date\")\n",
    "\n",
    "# Use .loc[] to subset temperatures_ind for rows in 2010 and 2011\n",
    "print(temperatures_ind.loc[\"2010\":\"2011\"])\n",
    "\n",
    "# Use .loc[] to subset temperatures_ind for rows from Aug 2010 to Feb 2011\n",
    "print(temperatures_ind.loc[\"2010-08\":\"2011-02\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 23rd row, 2nd column (index 22, 1)\n",
    "print(temperatures.iloc[22, 1])\n",
    "\n",
    "# Use slicing to get the first 5 rows\n",
    "print(temperatures.iloc[:5])\n",
    "\n",
    "# Use slicing to get columns 3 to 4\n",
    "print(temperatures.iloc[:, 2:4])\n",
    "\n",
    "# Use slicing in both directions at once\n",
    "print(temperatures.iloc[:5, 2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a year column to temperatures\n",
    "temperatures[\"year\"] = temperatures[\"date\"].dt.year\n",
    "\n",
    "# Pivot avg_temp_c by country and city vs year\n",
    "temp_by_country_city_vs_year = temperatures.pivot_table(index = [\"country\", \"city\"], columns = \"year\", values = \"avg_temp_c\")\n",
    "\n",
    "# See the result\n",
    "print(temp_by_country_city_vs_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset for Egypt to India\n",
    "temp_by_country_city_vs_year.loc[\"Egypt\":\"India\"]\n",
    "\n",
    "# Subset for Egypt, Cairo to India, Delhi\n",
    "temp_by_country_city_vs_year.loc[(\"Egypt\", \"Cairo\"):(\"India\", \"Delhi\")]\n",
    "\n",
    "# Subset in both directions at once\n",
    "temp_by_country_city_vs_year.loc[(\"Egypt\", \"Cairo\"):(\"India\", \"Delhi\"), 2005:2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the worldwide mean temp by year\n",
    "mean_temp_by_year = temp_by_country_city_vs_year.mean()\n",
    "\n",
    "# Find the year that had the highest mean temp\n",
    "print(mean_temp_by_year[mean_temp_by_year == mean_temp_by_year.max()])\n",
    "\n",
    "# Get the mean temp by city\n",
    "mean_temp_by_city = temp_by_country_city_vs_year.mean(axis=\"columns\")\n",
    "\n",
    "# Find the city that had the lowest mean temp\n",
    "print(mean_temp_by_city[mean_temp_by_city == mean_temp_by_city.min()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib.pyplot with alias plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Look at the first few rows of data\n",
    "print(avocados.head())\n",
    "\n",
    "# Get the total number of avocados sold of each size\n",
    "nb_sold_by_size = avocados.groupby(\"size\")[\"nb_sold\"].sum()\n",
    "\n",
    "# Create a bar plot of the number of avocados sold by size\n",
    "nb_sold_by_size.plot(kind=\"bar\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib.pyplot with alias plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the total number of avocados sold on each date\n",
    "nb_sold_by_date = avocados.groupby(\"date\")[\"nb_sold\"].sum()\n",
    "\n",
    "# Create a line plot of the number of avocados sold by date\n",
    "nb_sold_by_date.plot(kind=\"line\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of nb_sold vs avg_price with title\n",
    "avocados.plot(x=\"nb_sold\", y=\"avg_price\", kind=\"scatter\", title=\"Number of avocados sold vs. average price\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of conventional avg_price \n",
    "avocados[avocados[\"type\"] == \"conventional\"][\"avg_price\"].hist()\n",
    "\n",
    "# Histogram of organic avg_price\n",
    "avocados[avocados[\"type\"] == \"organic\"][\"avg_price\"].hist()\n",
    "\n",
    "# Add a legend\n",
    "plt.legend([\"conventional\", \"organic\"])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify histogram transparency to 0.5\n",
    "avocados[avocados[\"type\"] == \"conventional\"][\"avg_price\"].hist(alpha=0.5)\n",
    "\n",
    "# Modify histogram transparency to 0.5\n",
    "avocados[avocados[\"type\"] == \"organic\"][\"avg_price\"].hist(alpha=0.5)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend([\"conventional\", \"organic\"])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify bins to 20\n",
    "avocados[avocados[\"type\"] == \"conventional\"][\"avg_price\"].hist(alpha=0.5, bins=20)\n",
    "\n",
    "# Modify bins to 20\n",
    "avocados[avocados[\"type\"] == \"organic\"][\"avg_price\"].hist(alpha=0.5, bins=20)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend([\"conventional\", \"organic\"])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib.pyplot with alias plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check individual values for missing values\n",
    "print(avocados_2016.isna())\n",
    "\n",
    "# Check each column for missing values\n",
    "print(avocados_2016.isna().any())\n",
    "\n",
    "# Bar plot of missing values by variable\n",
    "avocados_2016.isna().sum().plot(kind=\"bar\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values\n",
    "avocados_complete = avocados_2016.dropna()\n",
    "\n",
    "# Check if any columns contain missing values\n",
    "print(avocados_complete.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the columns with missing values\n",
    "cols_with_missing = [\"small_sold\", \"large_sold\", \"xl_sold\"]\n",
    "\n",
    "# Create histograms showing the distributions cols_with_missing\n",
    "avocados_2016[cols_with_missing].hist()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From previous step\n",
    "cols_with_missing = [\"small_sold\", \"large_sold\", \"xl_sold\"]\n",
    "avocados_2016[cols_with_missing].hist()\n",
    "plt.show()\n",
    "\n",
    "# Fill in missing values with 0\n",
    "avocados_filled = avocados_2016.fillna(0)\n",
    "\n",
    "# Create histograms of the filled columns\n",
    "avocados_filled[cols_with_missing].hist()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of dictionaries with new data\n",
    "avocados_list = [\n",
    "    {\"date\": \"2019-11-03\", \"small_sold\": 10376832, \"large_sold\": 7835071},\n",
    "    {\"date\": \"2019-11-10\", \"small_sold\": 10717154, \"large_sold\": 8561348},\n",
    "]\n",
    "\n",
    "# Convert list into DataFrame\n",
    "avocados_2019 = pd.DataFrame(avocados_list)\n",
    "\n",
    "# Print the new DataFrame\n",
    "print(avocados_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of lists with new data\n",
    "avocados_dict = {\n",
    "  \"date\": [\"2019-11-17\", \"2019-12-01\"],\n",
    "  \"small_sold\": [10859987, 9291631],\n",
    "  \"large_sold\": [7674135, 6238096]\n",
    "}\n",
    "\n",
    "# Convert dictionary into DataFrame\n",
    "avocados_2019 = pd.DataFrame(avocados_dict)\n",
    "\n",
    "# Print the new DataFrame\n",
    "print(avocados_2019)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}